# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, metatron team
# This file is distributed under the same license as the metatron discovery docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: metatron discovery docs 0.4.2\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-02-08 00:00+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../discovery/part01/druid_tests.rst:2
# 869b6cea8eef412989f0fb1d1244f0c8
msgid "Druid 성능 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:7
# c47b30554b2147a8ac02a2aa972e00e9
msgid "Druid는 '실시간' 탐색이 가능한 데이터 스토어를 지향하는 만큼 수치화된 성능을 평가함에 있어서는 다음의 두 가지 측면에 초점이 맞춰집니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:9
# 023bb1a0ea8f4c539c62b3c64d5cc05e
msgid "Query latency"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:10
# fd99d8917d21410ca06ebe17963d3e3d
msgid "Ingestion latency"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:12
# 90b909f9dd1e4654860ff1b80902213d
msgid "쿼리 처리와 ingestion에서 소요되는 시간을 최소화하는 것이 '실시간'을 이루는 핵심이 되기 때문입니다. 지금까지 Druid 개발진을 비롯한 여러 기관 및 개인이 이러한 기준으로 Druid 성능을 평가한 benchmark들을 산출하고 그 밖의 지표를 통해 Druid를 다른 데이터베이스 관리 시스템들과 비교한 결과를 공개하였습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:16
# 4382f64d368145769192e7aa656d7378
msgid "Druid 개발진의 자체 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:18
# 72bc6c9a336744bfaa187eca12e79e91
msgid "Druid 개발진이 2014년 발표한 백서 'Druid: A Real-time Analytical Data Store'[#f1]_\\의 Chapter 6 Performance에서는 Druid의 query 및 ingestion latency를 다방면에서 평가한 결과를 상세하게 설명하고 있습니다. 본 절에서는 이 중에서 Druid의 성능을 직관적으로 살펴볼 수 있는 지표 위주로 간단히 소개합니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:21
# 62e17ab29236415c8e237cdec4307e9d
msgid "Query latency 성능"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:23
# 9596d564b6ce4c20a52c5796cfc2907e
msgid "Druid의 query latency 성능에 대해 백서에서는 현장에서 실제 사용되는 데이터셋 8종과 TPC-H 데이터셋에 대한 쿼리 결과를 기준으로 평가하였는데, 여기서는 TPC-H 데이터셋에 대한 쿼리 결과를 소개합니다. TPC-H 데이터셋에 대한 query latency는 MySQL과의 비교 평가 방식으로 진행하였고, 이때 사용한 클러스터 사양은 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:25
# aeaf90069bb5419a82f94d6a7dfe20ae
msgid "**Druid historical 노드:** Amazon EC2 m3.2xlarge instance types (Intel® Xeon® E5-2680 v2 @ 2.80GHz)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:26
# fcab465a39fd4299b43ea52751826839
msgid "**Druid broker 노드:** c3.2xlarge instances (Intel® Xeon® E5-2670 v2 @ 2.50GHz)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:27
# 7ee9082ebd844821966cd188b433d479
msgid "**MySQL Amazon RDS instance** (Druid와 동일한 m3.2xlarge instance type)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:29
# ff9278aea0b2489b88cbf772c11478f8
msgid "아래는 단일 노드에서의 1GB 및 100GB TPC-H 데이터셋에 대한 Druid와 MySQL의 query latency를 비교한 결과를 정리한 그래프입니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:35
#: ../../discovery/part01/druid_tests.rst:45
#: ../../discovery/part01/druid_tests.rst:62
# 99dbb84038ee4d7499fa50c5ff9b3798
# 1f6ffd63adfd44c3845b43dc497e0fb7
# a384d7b52473418f8d395eec272f090d
msgid "Source: Druid: A Real-time Analytical Data Store"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:37
# 710651a6d11d4ed5a72185e7bc715c99
msgid "이러한 결과는 Druid의 도입으로 기존 관계형 데이터베이스 시스템에 비해 획기적으로 빠른 쿼리 속도를 낼 수 있음을 시사합니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:39
# 5afa5d75198244d3b800cc1404f26f73
msgid "또한 여러 노드를 엮어서 클러스터를 구성할 경우 쿼리 처리 속도가 어느 정도 향상되는지도 측정하였습니다. 쿼리 대상 데이터셋으로서 100GB TPC-H를 사용하였으며 단일 노드(8개 코어)와 6개 노드 클러스터(48개 코어) 간의 성능 차이는 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:47
# 5de5f84e854b439581aec33d71fabd29
msgid "모든 쿼리가 linear scalability를 달성하지는 않았으나 상대적으로 단순한 쿼리들의 경우에는 거의 코어 수에 정비례하는 처리 속도 증대를 보여주었습니다(SK텔레콤 Metatron에서는 더욱 뚜렷한 linear scalability를 달성할 수 있도록 기능을 보강하였습니다)."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:50
# 36c90f1bd71443048c398ace18d07678
msgid "Ingestion latency 성능"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:52
# 74446d4dc4bc41f788d51dc0566f786e
msgid "Druid의 ingestion 성능에 대해서도 평가하였는데, 이때 사용된 클러스터 환경은 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:54
# 02bcbc2015284779a4f266223b166888
msgid "6개 노드, 총 메모리 360GB 및 96개 코어(12 x Intel® Xeon® E5-2670)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:56
# 096d269bcf36449fb6a821a6a6086cf3
msgid "ingestion 대상으로는 현장에서 실제 사용되는 데이터 소스 8종이었으며 데이터 소스 각각의 특징과 ingestion 결과는 아래와 같았습니다. 참고로 ingestion 측정을 하는 기간 동안 해당 클러스터에서는 그 외 다른 데이터 소스에 대한 ingestion 동작도 병행해서 실시하였습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:64
# f02e7a752abb48058e7930f40e4654ee
msgid "데이터 ingestion 속도는 데이터의 복잡성 등 여러 가지 변수의 영향을 받지만, 측정 결과를 놓고 볼 때 대체로 'interactivity'라는 Druid의 개발 목표에 부합한다고 할 수 있습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:68
# df2a00f85d624d1cbe7987767dce8c5d
msgid "SK텔레콤의 Druid 성능 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:70
# 7f9c3e6ada5f4996ab857f1434ef68cf
msgid "SK텔레콤에서는 다음과 같이 Druid의 query latency와 ingestion latency를 측정하였습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:73
# a3f378b327b7478ab4e07b7805b2c577
msgid "Query latency 테스트"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:75
# 077c56f4135440c2874dd6386593be87
msgid "Query latency를 측정하는 조건은 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:77
# 8e8db0cdc29a44eb87f9f432696466bf
msgid "데이터: TPC-H 100G dataset (9억 rows)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:78
# 622ed1b88ac34194b48f2a11704b0797
msgid "Pre-aggregation 기준: day"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:79
# aca09e706ef046eb98e0359a348ef366
msgid "서버: r3.4xlarge nodes, (2.5GHz * 16, 122G, 320G SSD) * 6"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:80
# 34e742285cc447b6b087f0f2493b9bfa
msgid "Historical 노드 개수: 6개"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:81
# 3fb660b920304f5ebe803db0c1869398
msgid "Broker 노드 개수: 1개"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:83
# 3ce3e26171ff43c8baec1142d9129cfb
msgid "그 결과 TPC-H 100G dataset의 5개 쿼리의 반환 속도는 다음과 같았습니다(Hive의 쿼리 처리 속도도 참조용으로 함께 측정하였습니다)."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:89
#: ../../discovery/part01/druid_tests.rst:113
# c04bbcc3d1244624a0928ac104c12314
# 0889314fbd8a4965ab78d2e536cd0b86
msgid "Source: SK Telecom T-DE WIKI Metatron Project"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:92
# 61df728018aa41fca2f322c53c68749d
msgid "Hive의 benchmark가 현저하게 떨어지는 원인 중 일부는 Thrift로 측정한 것과 partition없이 test set이 구성되어 있기 때문입니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:95
# e7b272ee620845d0b8d280068232bfb0
msgid "Ingestion latency 테스트"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:97
# 1959321e29fe421190165b22eb47ccee
msgid "Ingestion latency를 측정하는 조건은 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:99
# a19a5aac2ef94c2bb34072a9328e5e80
msgid "Ingestion data size: 1일 30억 rows, 10 columns"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:100
# ad131bedbf9645c6bbf46b021776c616
msgid "메모리: 512 GB"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:101
# 6326ad3475f14ea9a9122b24e6e4a5a6
msgid "CPU: Intel (R) Xeon (R) Gold 5120 CPU @ 2.20 GHz (core 56개)"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:102
# c195a5f450ea46cabb0cbbfc7190d9a2
msgid "Historical 노드 개수: 100개"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:103
# 36047f4e4a914433b14bd173563be73a
msgid "Broker 노드 개수: 2개"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:104
# ce0e6335380e46e08f75a617933bc1a2
msgid "총 10개의 middle manager 노드 중 3개에서 job 수행"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:105
# e69476f3c5cb411ab292db4b20536e95
msgid "Ingestion 도구: Apache Kafka"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:107
# 18f14b4e912349be8e5f1b67c6bd782c
msgid "이와 같은 조건으로 data ingestion을 100회 수행하였고 평균 ingestion latency는 1.623439초였습니다. 여기서 ingestion latency는 아래 도식화한 것과 같이 Kaka ingestion, Druid ingestion, Druid query 처리에 소요되는 시간을 모두 합산한 것입니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:116
# b476ddcab5034ff1a531b63d29a099aa
msgid "Druid에 대한 제3자의 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:119
# 8b4f83623e564a97a38f12b237fb9f69
msgid "Outlier의 Druid 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:121
# f40da681b2f0402da12aa87e66ee784b
msgid "다음은 Outlier 블로그에 2016년 8월 26일에 게재된 Top 10 Time Series Databases라는 포스트\\ [#f2]_\\에서는 20개의 주요 오픈소스 시계열 데이터베이스 시스템을 평가하였습니다. 기고자인 Steven Acreman이 개인적으로 매긴 성능 랭킹에서 Druid는 20개 중 9위를 차지하였는데, 여기서 밝힌 Druid의 주요 성능은 다음과 같습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:0
# 8b6c3206e2a946dda0e06dd5074f0354
msgid "Outlier의 주요 Druid 평가 내용"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 77d9083cb1d146bbb98738a6218764cf
msgid "평가 기준"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 9c3c4df8f037471f84d3a5be0a57e0c7
msgid "Druid의 성능"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 0d144b850d4a418bb4763d76cb9693d9
msgid "쓰기 성능 - 단일 노드"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 76527de658d049039605938daadf53d7
msgid "25k metrics/sec :raw-html:`<br />` 출처: https://groups.google.com/forum/#!searchin/druid-user/benchmark%7Csort:relevance/druid-user/90BMCxz22Ko/73D8HidLCgAJ"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 7f39426cd9714b14869144736f440b6f
msgid "쓰기 성능 - 5개 노드 클러스터"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# a52de029c2db4390953a4d6592da7f35
msgid "100k metrics/sec (추산 결과)"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 2cfbef09f8334c84abec076dd79e9111
msgid "쿼리 성능"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# cc9040be416b432b85e4483211dda4df
msgid "양호"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# adae40bf34dd4aeea7562aecd14bdbe0
msgid "개발 수준"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# ab0e9129fde04edab460005773040418
msgid "안정적인 제품을 제공하는 단계에 이름"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# e2b0a27bd65043be9f0293b7d20e47b2
msgid "장점"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 8d6d2d48184b48088ded0f5013b1ef1e
msgid "괜찮은 데이터 모델이면서 좋은 분석 도구 기능들을 갖추고 있음. 주로 batch 로드된 대량 데이터셋에 대해 신속하게 쿼리하는 데 사용되도록 설계되었으며, 이 점에서 탁월한 성능을 보임."
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# f57fce550e7f479182a10202d5e78ad9
msgid "단점"
msgstr ""

#: ../../discovery/part01/Assessment_by_Outlyer.csv:1
# 93900c5dde71499bb182ba6374682769
msgid "시스템 운용이 힘듦. 쓰기 처리 속도가 아주 빠르지는 않음. 실시간 ingestion 셋업이 까다로움"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:129
# 031ea47c420b4a6d8b9761779fcc40d0
msgid "DB-Engines의 Druid 평가"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:131
# a2e62ddf272e438eac0cbfbbfe9bf4f6
msgid "온라인 웹사이트 DB Engines\\ [#f3]_\\에서는 다양한 데이터베이스 관리 시스템(DBMS)의 시장 인기도를 매달 평가하며, 이때 다음과 같은 지표를 사용합니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:133
# b4aad46fb98147c99aa9dc7ba381671a
msgid "인터넷에서 언급되는 횟수: Google, Bing, Yandex에서의 검색 결과로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:134
# dffebbc515934a5da61cd9c2d125e944
msgid "일반적인 관심: Google Trends에서의 검색 빈도를 기준으로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:135
# 089c55ff76a244139895d28bc460070b
msgid "기술 토론 빈도: 유명 IT 관련 Q&A 사이트인 Stack Overflow 및 DBA Stack Exchange 포스팅 현황을 기준으로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:136
# 89c12cd53f544ce8aed3cf5ff8f16e3b
msgid "구인 게시글 수: Indeed 및 Simply Hired의 게시글을 기준으로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:137
# 0dcc2bb001404d1cac72f9d58867f5e7
msgid "해당 커리어를 지닌 인재의 수: LinkedIn 및 Upwork에 게시된 프로필을 기준으로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:138
# 40fc1ddb572348718701d2bb58d4f97f
msgid "SNS에서의 언급 수: Twitter의 트윗수를 기준으로 측정"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:140
# b124e5f523db44cdbd89727da42d581a
msgid "그 결과 Druid는 2018년 7월 기준으로 총 343개 시스템 중에서 118위를 차지하였고, 그 중 시계열 데이터베이스 시스템만을 두고 집계했을 때 총 25개 시스템 중 7위를 차지하였습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:143
# 424acb10beeb4bb29ee463970cbd62f7
msgid "Apache Spark와의 비교"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:145
# a704f3c190bd4ce1af20bd6dc2ef0966
msgid "Druid를 Apache Spark와 비교하는 것은 상당히 의미 있는 작업입니다. 둘 다 차세대 대용량 데이터 분석 솔루션으로 각광 받고 있으며, 서로 다른 장점을 가지고 있어 매우 상호보완적으로 조합이 가능하기 때문입니다. Metatron에서도 Druid를 데이터 저장/처리용 엔진으로 사용하고 Spark를 고급 분석용 모듈로 사용함으로써 이들 간의 시너지를 잘 활용하고 있습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:147
# 6106bb5737874bcbb06e5a540fdb8e37
msgid "여기서는 Sparkline Data Inc.의 창업자 Harish Butani가 공개한 Druid vs Spark 성능 비교 보고서\\ [#f4]_\\ [#f5]_\\의 내용을 간단히 소개합니다. 보고서에서는 애초에 두 솔루션이 경쟁 관계에 있다기 보다는 상보적인 역할을 한다고 상정을 하고 성능 비교를 시작합니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:150
# d6294ecf72d94f98b0be7d68d9f90efd
msgid "Apache Spark의 특징"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:152
# 86bfde529b2142d2bdeff2a19a89750f
msgid "Apache Spark는 오픈소스 클러스터 컴퓨팅 프레임워크로서 Java, Scala, Python, R 언어로 이루어진 다양한 API를 제공합니다. Spark의 프로그래밍 모델은 SQL, 머신러닝, 그래프 프로세싱을 결합한 분석 솔루션을 구축하는 것입니다. Spark는 규모가 크거나 복잡한 데이터를 가공할 수 있도록 강력한 기능들을 지원하지만, Druid와 같은 interactive한 쿼리 처리에 최적화되지는 않았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:155
# 62b8ddd05bce4a048450f494d5bbd1ac
msgid "데이터셋, 쿼리, 성능 비교 결과"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:157
# 028887f4fb814ece922779f275cac3d1
msgid "본 성능 비교를 위한 데이터셋으로 TPCH 10G benchmark data set을 이용했습니다. 본래 이 데이터셋은 관계형 데이터베이스에 적합한 스타 스키마 구조를 갖기 때문에 이를 역정규화시킨 후 Druid와 Spark에서 처리할 수 있도록 재구성하였습니다. 이러한 처리를 거친 데이터셋의 크기는 각각 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:159
# 4c4d26ef549f491c86fcddb8513a28da
msgid "TPCH Flat TSV: 46.80GB"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:160
# 59f07596497e416298dbbce26a0d0592
msgid "Druid Index in HDFS: 17.04GB"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:161
# 102fb3f9c33f44bbab3fabd152147d91
msgid "TPCH Flat Parquet: 11.38GB"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:162
# ec25dda21ea84c75a6f1c22715d02ecc
msgid "TPCH Flat Parquet Partition by Month: 11.56GB"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:164
# 5bbb655befee4691b8dfbd77fad2175a
msgid "그런 다음 두 솔루션의 쿼리 처리 속도를 다각도에서 분석할 수 있는 여러 쿼리를 아래와 같이 구성하였습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:0
# 3d98554556444a3496cd34f8a4bf6e64
msgid "Druid와 Apache Spark의 query latency 비교 평가에 사용된 쿼리 내역"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# d57ee5adeb004940b95ce4601227c33e
msgid "Query"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 88cb616281fd44ca96a0a76dc4ff6450
msgid "Interval"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# a26708bdb0aa43049b0120d2189354c1
msgid "Filters"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 45f11a4eedf344819ea5010e51abd117
msgid "Group By"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# e9551f9925604f029ccde43c9c0e01a1
msgid "Aggregations"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 07321f8ded6c45f9b2eca2e5bf86337a
msgid "Basic Aggregation."
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 6c1029eaba0b43bdbded68ff03737cff
# c4526b1889db414d8b56d6774b9ee34e
# e9567298ff374112989b025bee1a0a55
# 6283fe9fd5104e9d81ff94d7d3682f3e
# 7803d361200b4688985c3fad60de7675
# 3f60a3844b414e73b7cd91c7412fc6c9
# 58ef4bc411bb423e8c76d6eb82245714
# 0691cc748dc141a49a992bb7cb1ca385
msgid "None"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 0330dce7851b4496beaff9a6af05ca36
# 17fb3d675fb64519924206c6ecfe610f
# d75f5e45b0d04df8b12ad1cbd3945bd7
msgid "ReturnFlag :raw-html:`<br />` LineStatus"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 30a228c850524f8da9410b1e2d1fc735
msgid "Count(*) :raw-html:`<br />` Sum(exdPrice) :raw-html:`<br />` Avg(avlQty)"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 2cb2cd65326a46e78edf0f11022b3a5d
msgid "Ship Date Range"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 622a0be482d24a78bb36e68a70f00c19
# 4e9b38155d7240b7abab7f874d0307ac
msgid "1995-12/1997-09"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 4081833669814ddf991fea315457df86
msgid "Count(*)"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# bf4a988dc74c40a3914610c31d6ca3d1
msgid "SubQry :raw-html:`<br />` Nation, pType :raw-html:`<br />` ShpDt Range"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 7db13c04e4a1410c9c8e6185efbf6c51
msgid "P_Type :raw-html:`<br />` S_Nation + :raw-html:`<br />` C_Nation"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 9ad6b1fbaca640daa5df39199c2b86db
# a14ddc19fa4f45238b22920e215b0751
msgid "S_Nation"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# efdd92a5d1a64dc9a9bdfbf90efe1f52
# 28d25729b39741c7ab3d4c01f2580ae6
msgid "Count(*) :raw-html:`<br />` Sum(exdPrice) :raw-html:`<br />` Max(sCost) :raw-html:`<br />` Avg(avlQty) :raw-html:`<br />` Count(Distinct oKey)"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 3563feebc5ff4240b762cf2868229de1
msgid "TPCH Q1"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 0ea067db0b3c4e098191a546cdf276d0
msgid "TPCH Q3"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 6bb134cb31c841e28f2aee6e33ded96f
msgid "1995-03-15-"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# cd85218a4ece4d33a08eefc48b896f57
msgid "O_Date :raw-html:`<br />` MktSegment"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 902f4f170fe34ea991ec3947ae28be67
msgid "Okey :raw-html:`<br />` Odate :raw-html:`<br />` ShipPri"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 9e55bc344c7b4b57b5e5cc528b3a6075
# 02fbe1f499194c2381b8fff7810c74f2
# 40ae3067945044898a5b23c959390ee8
# 9691843b16f24440b9eba862d4b71a44
msgid "Sum(exdPrice)"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# d9e287c08b31425f862c7da8a59d714b
msgid "TPCH Q5"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 65382c698faa41d3889728cb4964f5e5
msgid "O_Date :raw-html:`<br />` Region"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# e454436ace0e49f196a453233bb1364d
msgid "TPCH Q7"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# fec085e4de0f4890a20247fde3acce00
msgid "S_Nation + :raw-html:`<br />` C_Nation"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 5ce29bd6cec44b6e9b1b83e7534b024a
msgid "S_Nation :raw-html:`<br />` C_Nation :raw-html:`<br />` ShipDate.Year"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# b64fb73d030d47399eb932d91219416d
msgid "TPCH Q8"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# d61ce887e351451eb51bfc512aad3809
msgid "Region :raw-html:`<br />` Type :raw-html:`<br />` O_Date"
msgstr ""

#: ../../discovery/part01/comparison_with_Apache_Spark.csv:1
# 6e987146586e4712a2e8862a0b6d4ff0
msgid "ODate.Year"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:171
# 861ffac957694b098bfa94ef86100b2c
msgid "테스트 결과는 다음과 같았습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:177
# d1f8116906814dd58ca38b8c1c805f1b
msgid "Source: Combining Druid and Spark: Interactive and Flexible Analytics at Scale"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:179
# f7d858b42f2c4dbe9c8051a133a5ea77
msgid "Filters + Ship Date 쿼리는 Druid에 특화된 slice-and-dice 성능을 테스트하는 것이었고, 예상대로 무려 50배 이상 속도 상에 우위를 보였습니다. 마찬가지로 TPCH Q7 쿼리를 처리하는 데도 Druid에서 수 밀리초가 소요된 반면, Spark에서는 수초가 소요되었습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:180
# 1d4e22eb382640df8f1db3ba6f5f841d
msgid "TPCH Q3, Q5, Q8 쿼리의 경우에는 Druid가 위 경우와 같은 극대화된 효율성을 보여주지 못했습니다. OrderDate 술어는 Druid에서 JavaScript 필터로 번역이 되는데, 이는 네이티브 Java 필터에 비해 현저히 느리기 때문입니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:181
# bf0218dfa4af4a0da5804cbb85000c4d
msgid "Basic Aggregation 및 TPCH Q1 쿼리의 경우에도 Druid에서 훨씬 빠른 처리 속도를 보여주었습니다. Druid에서는 Count-Distinct 동작이 cardinality aggregator로 번역이 되는데, 이는 approximate count에 해당합니다. 이러한 장점 덕에 Druid는 cardinality가 큰 차원들을 탐색할 때 유리합니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:183
# 9aa5ed97b2724f4e921a5dfeef0defc9
msgid "여러 가지 조건에 따라 결과는 달라질 수 있지만, 한 가지 분명한 것은 시간 파티셔닝(time partitioning) 또는 차원 술어(dimensional predicates)를 포함하는 쿼리는 Druid에서 현저히 빠르게 처리한다는 것입니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:187
# 58ad7b9c84c4463d8f1e38b1c499923d
msgid "시사점"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:189
# 08b50037db9f42cda0290002852c9dda
msgid "이러한 테스트 결과는 Druid의 초고속 쿼리 처리 능력과 Spark의 고급 분석 기능을 결합하면 아주 훌륭한 시너지 효과를 기대할 수 있음을 시사합니다. Druid를 통해 신속하고 효율적으로 분석에 필요한 데이터만 추려낸 후 Spark의 풍부한 프로그래밍 API들을 활용하여 심층적인 분석을 실시하는 것입니다. 이렇게 함으로써 강력하고 유연하며 쿼리 latency가 매우 낮은 분석 솔루션을 구축할 수 있습니다."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:192
# aefff2c824ff42688e053b796551d379
msgid "참고자료"
msgstr ""

#: ../../discovery/part01/druid_tests.rst:193
# 3217a8e56d094444a77b2ce46e086e75
msgid "Yang, E. Tschetter, X. Léauté, N. Ray, G. Merlino, and D. Ganguli. (2014). `Druid: a real-time analytical data store`. Retrieved from http://druid.io/docs/0.12.1/design/index.html."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:194
# 7b866b1512fc47e9b92d1fbcf83b5096
msgid "Steven Acreman. (2016, Aug 26). `Top 10 Time Series Databases`. Retrieved from https://blog.outlyer.com/top10-open-source-time-series-databases."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:195
# f2b81ca34f074034bf93bc03e218e99e
msgid "DB-Engines website. https://db-engines.com, July 2018."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:196
# a5ab088dad694626872c16b1894e928c
msgid "Harish Butani. (2018, Sep 18). Combining Druid and Spark: Interactive and Flexible Analytics at Scale. Retrieved from https://www.linkedin.com/pulse/combining-druid-spark-interactiveflexible-analytics-scale-butani."
msgstr ""

#: ../../discovery/part01/druid_tests.rst:197
# bda7451780384bc0beb452bd9c501998
msgid "Harish Butani. (2015, Aug 28). TPCH Benchmark. Retrieved from https://github.com/SparklineData/spark-druid-olap/blob/master/docs/benchmark/BenchMarkDetails.pdf."
msgstr ""

